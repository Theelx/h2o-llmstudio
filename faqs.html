<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-faqs">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">FAQs | H2O LLM Studio | Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.h2o.ai/h2o-llmstudio/faqs"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="sitename" content="H2O LLM Studio | Docs"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="FAQs | H2O LLM Studio | Docs"><meta data-rh="true" name="description" content="Learn about frequently asked questions."><meta data-rh="true" property="og:description" content="Learn about frequently asked questions."><link data-rh="true" rel="icon" href="/h2o-llmstudio/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.h2o.ai/h2o-llmstudio/faqs"><link data-rh="true" rel="alternate" href="https://docs.h2o.ai/h2o-llmstudio/faqs" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.h2o.ai/h2o-llmstudio/faqs" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://ADXS57JGWZ-dsn.algolia.net" crossorigin="anonymous"><link rel="search" type="application/opensearchdescription+xml" title="H2O LLM Studio | Docs" href="/h2o-llmstudio/opensearch.xml">

<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"><link rel="stylesheet" href="/h2o-llmstudio/assets/css/styles.be3f536b.css">
<link rel="preload" href="/h2o-llmstudio/assets/js/runtime~main.cca6fbe9.js" as="script">
<link rel="preload" href="/h2o-llmstudio/assets/js/main.b23f85b2.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://docs.h2o.ai/haic-documentation/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/h2o-llmstudio/img/h2oai.png" alt="H2O AI Cloud logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/h2o-llmstudio/img/h2oai.png" alt="H2O AI Cloud logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Documentation</b></a><div class="navbarItems_fVuF"><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Platform</a><ul class="dropdown__menu"><li><a href="https://docs.h2o.ai/h2o-ai-cloud/get-started/what-is-ai-app-store" target="_blank" rel="noopener noreferrer" class="dropdown__link">AI App Store</a></li><li><a href="https://h2oai.github.io/featurestore/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Feature Store</a></li><li><a href="https://docs.h2o.ai/wave-mc-admin-center/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Admin Center</a></li><li><a href="https://docs.h2o.ai/h2o-drive/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Drive</a></li><li><a href="https://docs.h2o.ai/haic-documentation/" target="_blank" rel="noopener noreferrer" class="dropdown__link">HAIC Platform</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Applications</a><ul class="dropdown__menu"><li><a href="https://docs.h2o.ai/wave-apps/h2o-autodoc/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O AutoDoc</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-autoinsights/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O AutoInsights</a></li><li><a href="https://docs.h2o.ai/notebook/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Notebook Labs</a></li><li><a href="https://docs.h2o.ai/wave-apps/ai-unit-consumption/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O AI Unit Consumption</a></li><li><a href="https://docs.h2o.ai/h2o-drive/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Drive</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-label-genie/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Label Genie</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-model-analyzer/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Model Analyzer</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-model-validation/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Model Validation</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-model-security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Model Security</a></li><li><a href="https://docs.h2o.ai/wave-apps/admin-analytics/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Admin Analytics</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Models</a><ul class="dropdown__menu"><li><a href="https://docs.h2o.ai/h2o-escorer/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O eScorer</a></li><li><a href="https://docs.h2o.ai/mlops/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O MLOps</a></li><li><a href="https://docs.h2o.ai/wave-apps/admin-analytics/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Admin Analytics</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-model-analyzer/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Model Analyzer</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-model-validation/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Model Validation</a></li><li><a href="https://docs.h2o.ai/wave-apps/h2o-model-security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Model Security</a></li><li><a href="https://docs.h2o.ai/h2o-escorer/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O eScorer</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">AI Engines</a><ul class="dropdown__menu"><li><a href="https://h2oai.github.io/ai-engine-manager/" target="_blank" rel="noopener noreferrer" class="dropdown__link">AI Engine Manager</a></li><li><a href="https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Driverless AI</a></li><li><a href="https://docs.h2o.ai/h2o-document-ai/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Document AI</a></li><li><a href="https://docs.h2o.ai/h2o-hydrogen-torch/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Hydrogen Torch</a></li><li><a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O-3</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">GenAI</a><ul class="dropdown__menu"><li><a href="https://github.com/h2oai/h2ogpt#readme" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O GPT</a></li><li><a href="https://docs.h2o.ai/h2ogpte-docs/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Enterprise h2oGPTe</a></li><li><a href="https://docs.h2o.ai/h2o-llm-data-studio/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O LLM DataStudio</a></li><li><a href="https://docs.h2o.ai/h2o-llmstudio/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O LLM Studio</a></li><li><a href="https://docs.h2o.ai/eval-studio-docs/" target="_blank" rel="noopener noreferrer" class="dropdown__link">H2O Eval Studio</a></li></ul></div></div></div><div class="navbar__items navbar__items--right"><span class="versionLabel_pQWd"> </span><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button><div class="navbarButtons_f03l"><a href="https://h2o.ai/platform/ai-cloud/" target="_blank" rel="noopener noreferrer"><button class="button navbar-button navbar-button--primary">Learn More</button></a><a href="https://h2o.ai/demo/" target="_blank" rel="noopener noreferrer"><button class="button navbar-button navbar-button--secondary">Request a Demo</button></a></div><div class="toggle_vylO colorModeToggle_x44X"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/h2o-llmstudio/">H2O LLM Studio | Docs</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/h2o-llmstudio/get-started/what-is-h2o-llm-studio">Get started</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/h2o-llmstudio/concepts">Concepts</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/h2o-llmstudio/guide/datasets/data-connectors-format">Guide</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/h2o-llmstudio/faqs">FAQs</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/h2o-llmstudio/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">FAQs</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>FAQs</h1><p>The sections below provide answers to frequently asked questions. If you have additional questions, please send them to <a href="mailto:cloud-feedback@h2o.ai" target="_blank" rel="noopener noreferrer">cloud-feedback@h2o.ai</a>.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-the-general-recommendations-for-using-h2o-llm-studio">What are the general recommendations for using H2O LLM Studio?<a href="#what-are-the-general-recommendations-for-using-h2o-llm-studio" class="hash-link" aria-label="Direct link to What are the general recommendations for using H2O LLM Studio?" title="Direct link to What are the general recommendations for using H2O LLM Studio?">​</a></h3><p>The recommendation is to always start with the default settings. From there, the parameters that tend to have the largest impact are: </p><ul><li>the LLM backbone</li><li>the number of epochs</li><li>the learning rate</li><li>the LoRA settings </li></ul><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>For more information on experiment settings, see <a href="/h2o-llmstudio/guide/experiments/experiment-settings">Experiment Settings</a>. </p></div></div><p>The parameters that have the largest impact on the amount of GPU memory being used are the <a href="/h2o-llmstudio/guide/experiments/experiment-settings#backbone-dtype">backbone dtype</a> and the <a href="/h2o-llmstudio/guide/experiments/experiment-settings#max-length">max length</a> (the length of the input sequence being used during model training). </p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>For more information, see <a href="#i-encounter-gpu-out-of-memory-issues-what-can-i-change-to-be-able-to-train-large-models">this FAQ about GPU out-of-memory issues</a>. </p></div></div><p>While these parameters will change the behavior of the fine-tuned model, the change that will be most impactful is the actual data used for fine tuning. Having clean data and enough samples (i.e., atleast 1000 records) is imperative.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="is-the-tool-multi-user-or-single-user">Is the tool multi-user or single user?<a href="#is-the-tool-multi-user-or-single-user" class="hash-link" aria-label="Direct link to Is the tool multi-user or single user?" title="Direct link to Is the tool multi-user or single user?">​</a></h3><p>While it is possible for multiple users to use the same instance, the tool was created for a single user at a time. </p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-can-human-feedback-be-applied-in-llm-studio">How can human feedback be applied in LLM Studio?<a href="#how-can-human-feedback-be-applied-in-llm-studio" class="hash-link" aria-label="Direct link to How can human feedback be applied in LLM Studio?" title="Direct link to How can human feedback be applied in LLM Studio?">​</a></h3><p>In order to apply human feedback to H2O LLM Studio, there is a problem type called DPO (Direct Preference Optimization), which is specifically used for learning human feedback. For these types of use cases, there would be a selected answer and a rejected answer column to train a reward model. This is a more stable form of the traditional RLHF. For more information, see <a href="https://arxiv.org/abs/2305.18290" target="_blank" rel="noopener noreferrer">this paper about DPO</a> by Stanford University.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-does-h2o-llm-studio-evaluate-the-fine-tuned-model">How does H2O LLM Studio evaluate the fine-tuned model?<a href="#how-does-h2o-llm-studio-evaluate-the-fine-tuned-model" class="hash-link" aria-label="Direct link to How does H2O LLM Studio evaluate the fine-tuned model?" title="Direct link to How does H2O LLM Studio evaluate the fine-tuned model?">​</a></h3><p>The valuation options are <a href="/h2o-llmstudio/concepts#bleu">BLEU</a>, <a href="/h2o-llmstudio/concepts#perplexity">Perplexity</a>, and an AI Judge. For more information about the traditional NLP similarity metrics, see <a href="/h2o-llmstudio/concepts#bleu">BLEU</a> and <a href="/h2o-llmstudio/concepts#perplexity">Perplexity</a> explained on the concepts page. You can also opt to use an AI judge by having an LLM model (ChatGPT or a local LLM) judge the performance of the response. This <a href="https://github.com/h2oai/h2o-llmstudio/blob/main/prompts/general.txt" target="_blank" rel="noopener noreferrer">sample prompt</a> is an example of a prompt that is used to have the LLM evaluate the response.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="can-i-use-a-different-ai-judge-than-chatgpt">Can I use a different AI Judge than ChatGPT?<a href="#can-i-use-a-different-ai-judge-than-chatgpt" class="hash-link" aria-label="Direct link to Can I use a different AI Judge than ChatGPT?" title="Direct link to Can I use a different AI Judge than ChatGPT?">​</a></h3><p>Yes. For instructions on how to use a local LLM to evaluate the fine-tuned model, see <a href="/h2o-llmstudio/guide/experiments/evaluate-model-using-llm">Evaluate model using an AI judge</a>. </p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-much-data-is-generally-required-to-fine-tune-a-model">How much data is generally required to fine-tune a model?<a href="#how-much-data-is-generally-required-to-fine-tune-a-model" class="hash-link" aria-label="Direct link to How much data is generally required to fine-tune a model?" title="Direct link to How much data is generally required to fine-tune a model?">​</a></h3><p>There is no clear answer. As a rule of thumb, 1000 to 50000 samples of conversational data should be enough. Quality and diversity is very important. Make sure to try training on a subsample of data using the &quot;sample&quot; parameter to see how big the impact of the dataset size is. Recent studies suggest that less data is needed for larger foundation models.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="are-there-any-recommendations-for-which-backbone-to-use-are-some-backbones-better-for-certain-types-of-tasks">Are there any recommendations for which backbone to use? Are some backbones better for certain types of tasks?<a href="#are-there-any-recommendations-for-which-backbone-to-use-are-some-backbones-better-for-certain-types-of-tasks" class="hash-link" aria-label="Direct link to Are there any recommendations for which backbone to use? Are some backbones better for certain types of tasks?" title="Direct link to Are there any recommendations for which backbone to use? Are some backbones better for certain types of tasks?">​</a></h3><p>The majority of the LLM backbones are trained on a very similar corpus of data. The main difference is the size of the model and the number of parameters. Usually, the larger the model, the better they are. The larger models also take longer to train. It is recommended to start with the smallest model and then increase the size if the performance is not satisfactory. If you are looking to train for tasks that are not directly question answering in English, it is also a good idea to look for specialized LLM backbones.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-if-my-data-is-not-in-question-and-answer-form-and-i-just-have-documents-how-can-i-fine-tune-the-llm-model">What if my data is not in question-and-answer form and I just have documents? How can I fine-tune the LLM model?<a href="#what-if-my-data-is-not-in-question-and-answer-form-and-i-just-have-documents-how-can-i-fine-tune-the-llm-model" class="hash-link" aria-label="Direct link to What if my data is not in question-and-answer form and I just have documents? How can I fine-tune the LLM model?" title="Direct link to What if my data is not in question-and-answer form and I just have documents? How can I fine-tune the LLM model?">​</a></h3><p>To train a chatbot style model, you need to convert your data into a question and answer format.</p><p>If you really want to continue pretraining on your own data without teaching a question-answering style, prepare a dataset with all your data in a single column Dataframe. Make sure that the length of the text in each row is not too long. In the experiment setup, remove all additional tokens (e.g. <code>&lt;|prompt|&gt;</code>, <code>&lt;|answer|&gt;</code>, for Text Prompt Start and Text Answer Start respectively) and disable <strong>Add Eos Token To Prompt</strong> and <strong>Add Eos Token To Answer</strong>. Deselect everything in the Prompt Column.</p><p>There are also other enterprise solutions from H2O.ai that may help you convert your data into a Q&amp;A format. For more information, see <a href="https://h2o.ai/" target="_blank" rel="noopener noreferrer">H2O.ai&#x27;s Generative AI page</a> and this blogpost about <a href="https://h2o.ai/blog/2023/streamlining-data-preparation-for-fine-tuning-of-large-language-models/" target="_blank" rel="noopener noreferrer">H2O LLM DataStudio: Streamlining Data Curation and Data Preparation for LLMs related tasks</a>.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="can-the-adapter-be-downloaded-after-fine-tuning-so-that-the-adapter-can-be-combined-with-the-backbone-llm-for-deployment">Can the adapter be downloaded after fine-tuning so that the adapter can be combined with the backbone LLM for deployment?<a href="#can-the-adapter-be-downloaded-after-fine-tuning-so-that-the-adapter-can-be-combined-with-the-backbone-llm-for-deployment" class="hash-link" aria-label="Direct link to Can the adapter be downloaded after fine-tuning so that the adapter can be combined with the backbone LLM for deployment?" title="Direct link to Can the adapter be downloaded after fine-tuning so that the adapter can be combined with the backbone LLM for deployment?">​</a></h3><p>H2O LLM Studio provides the option to download only the LoRA adapter when a model was trained with LoRA. Once the experiment has finished running, click the <strong>Download adapter</strong> button to download the lora adapter_weights separately from a fine-tuned model. </p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="i-encounter-gpu-out-of-memory-issues-what-can-i-change-to-be-able-to-train-large-models">I encounter GPU out-of-memory issues. What can I change to be able to train large models?<a href="#i-encounter-gpu-out-of-memory-issues-what-can-i-change-to-be-able-to-train-large-models" class="hash-link" aria-label="Direct link to I encounter GPU out-of-memory issues. What can I change to be able to train large models?" title="Direct link to I encounter GPU out-of-memory issues. What can I change to be able to train large models?">​</a></h3><p>There are various parameters that can be tuned while keeping a specific LLM backbone fixed. It is advised to choose 4bit/8bit precision as a backbone dtype to be able to train models &gt;=7B on a consumer type GPU. <a href="/h2o-llmstudio/concepts#lora-low-rank-adaptation">LORA</a> should be enabled. Besides that there are the usual parameters such as batch size and maximum sequence length that can be decreased to save GPU memory (please ensure that your prompt+answer text is not truncated too much by checking the train data insights).</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="when-does-the-model-stop-the-fine-tuning-process">When does the model stop the fine-tuning process?<a href="#when-does-the-model-stop-the-fine-tuning-process" class="hash-link" aria-label="Direct link to When does the model stop the fine-tuning process?" title="Direct link to When does the model stop the fine-tuning process?">​</a></h3><p>The number of epochs are set by the user.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-the-maximum-dataset-size-that-an-llm-studio-instance-can-handle">What is the maximum dataset size that an LLM Studio instance can handle?<a href="#what-is-the-maximum-dataset-size-that-an-llm-studio-instance-can-handle" class="hash-link" aria-label="Direct link to What is the maximum dataset size that an LLM Studio instance can handle?" title="Direct link to What is the maximum dataset size that an LLM Studio instance can handle?">​</a></h3><p>The total dataset size is basically unlimited / only bound by disk space as all training is done in batches. There is no specific rule of thumb for maximum batch size - this depends strongly on backbone, context size, use of flash attention 2.0, use of gradient checkpointing, etc.
We suggest using a batch size that just fills the RAM for maximum efficiency. While testing for maximum memory consumption, set padding quantile to <code>0</code>. Make sure to set it back to <code>1</code> when you have found a good setting for the batch size to save on runtime.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="where-does-h2o-llm-studio-store-its-data">Where does H2O LLM Studio store its data?<a href="#where-does-h2o-llm-studio-store-its-data" class="hash-link" aria-label="Direct link to Where does H2O LLM Studio store its data?" title="Direct link to Where does H2O LLM Studio store its data?">​</a></h3><p>By default, H2O LLM Studio stores its data in two folders located in the root directory in the app. The folders are named <code>data</code> and <code>output</code>. Here is the breakdown of the data storage structure:</p><ul><li><code>data/dbs</code>: This folder contains the user database used within the app.</li><li><code>data/user</code>: This folder is where uploaded datasets from the user are stored.</li><li><code>output/user</code>: All experiments conducted in H2O LLM Studio are stored in this folder. For each experiment, a separate folder is created within the <code>output/user</code> directory, which contains all the relevant data associated with that particular experiment.</li><li><code>output/download</code>: Utility folder that is used to store data the user downloads within the app. </li></ul><p>It is possible to change the default working directory of H2O LLM Studio by setting the <code>H2O_LLM_STUDIO_WORKDIR</code> environment variable. By default, the working directory is set to the root directory of the app.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-can-i-update-h2o-llm-studio">How can I update H2O LLM Studio?<a href="#how-can-i-update-h2o-llm-studio" class="hash-link" aria-label="Direct link to How can I update H2O LLM Studio?" title="Direct link to How can I update H2O LLM Studio?">​</a></h3><p>To update H2O LLM Studio, you have two options:</p><ol><li>Using the latest main branch: Execute the commands <code>git checkout main</code> and <code>git pull</code> to obtain the latest updates from the main branch.</li><li>Using the latest release tag: Execute the commands <code>git pull</code> and <code>git checkout v0.0.3</code> (replace &#x27;v0.0.3&#x27; with the desired version number) to switch to the latest release branch.</li></ol><p>The update process does not remove or erase any existing data folders or experiment records. This means that all your old data, including the user database, uploaded datasets, and experiment results, will still be available to you within the updated version of H2O LLM Studio.</p><p>Before updating, it is recommended to run the <code>git rev-parse --short HEAD</code> command and save the commit hash.
This will allow you to revert to your existing version if needed. </p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="once-i-have-the-lora-what-is-the-recommended-way-of-utilizing-it-with-the-base-model">Once I have the <a href="/h2o-llmstudio/guide/experiments/experiment-settings#lora">LoRA</a>, what is the recommended way of utilizing it with the base model?<a href="#once-i-have-the-lora-what-is-the-recommended-way-of-utilizing-it-with-the-base-model" class="hash-link" aria-label="Direct link to once-i-have-the-lora-what-is-the-recommended-way-of-utilizing-it-with-the-base-model" title="Direct link to once-i-have-the-lora-what-is-the-recommended-way-of-utilizing-it-with-the-base-model">​</a></h3><p>You can also export the LoRA weights. You may add them to the files to be exported <a href="https://github.com/h2oai/h2o-llmstudio/blob/main/llm_studio/app_utils/sections/experiment.py#L1552" target="_blank" rel="noopener noreferrer">here</a>. Before exporting, the LoRA weights are merged back into the original LLM backbone weights to make downstream tasks easier. You do not need to have PEFT, or anything else for your deployment.</p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-h2o-llm-studio-in-windows">How to use H2O LLM Studio in Windows?<a href="#how-to-use-h2o-llm-studio-in-windows" class="hash-link" aria-label="Direct link to How to use H2O LLM Studio in Windows?" title="Direct link to How to use H2O LLM Studio in Windows?">​</a></h3><p>Use WSL 2 on Windows </p><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-can-i-easily-fine-tune-a-large-language-model-llm-using-the-command-line-interface-cli-of-h2o-llm-studio-when-i-have-limited-gpu-memory">How can I easily fine-tune a large language model (LLM) using the command-line interface (CLI) of H2O LLM Studio when I have limited GPU memory?<a href="#how-can-i-easily-fine-tune-a-large-language-model-llm-using-the-command-line-interface-cli-of-h2o-llm-studio-when-i-have-limited-gpu-memory" class="hash-link" aria-label="Direct link to How can I easily fine-tune a large language model (LLM) using the command-line interface (CLI) of H2O LLM Studio when I have limited GPU memory?" title="Direct link to How can I easily fine-tune a large language model (LLM) using the command-line interface (CLI) of H2O LLM Studio when I have limited GPU memory?">​</a></h3><p>If you have limited GPU memory but still want to fine-tune a large language model using H2O LLM Studio&#x27;s CLI, there are alternative methods you can use to get started quickly.</p><ul><li><a href="https://www.kaggle.com/code/ilu000/h2o-llm-studio-cli/" target="_blank" rel="noopener noreferrer">Using Kaggle kernels</a> </li><li><a href="https://colab.research.google.com/drive/1soqfJjwDJwjjH-VzZYO_pUeLx5xY4N1K?usp=sharing" target="_blank" rel="noopener noreferrer">Using Google Colab</a></li></ul><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="can-i-run-a-validation-metric-on-a-model-post-training-optionally-on-a-different-validation-dataset">Can I run a validation metric on a model post-training, optionally on a different validation dataset?<a href="#can-i-run-a-validation-metric-on-a-model-post-training-optionally-on-a-different-validation-dataset" class="hash-link" aria-label="Direct link to Can I run a validation metric on a model post-training, optionally on a different validation dataset?" title="Direct link to Can I run a validation metric on a model post-training, optionally on a different validation dataset?">​</a></h3><p>Yes.</p><ol><li><p>After you have finished creating an experiment, click on the <span class="material-icons MuiIcon-root" aria-hidden="true">more_vert</span> Kebab menu of the relevant experiment and select <strong>New Experiment</strong>. </p></li><li><p>Enable the <strong>Use previous experiments weight</strong> setting found at the top of the screen.
This will now load the previous weights, and you can now change eval dataset, metric, and anything else as you see fit. To only do evaluation without any retraining, set the <strong>Epochs</strong> to 0.</p></li></ol><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-the-hardwareinfrastructure-sizing-recommendations-for-h2o-llm-studio">What are the hardware/infrastructure sizing recommendations for H2O LLM Studio?<a href="#what-are-the-hardwareinfrastructure-sizing-recommendations-for-h2o-llm-studio" class="hash-link" aria-label="Direct link to What are the hardware/infrastructure sizing recommendations for H2O LLM Studio?" title="Direct link to What are the hardware/infrastructure sizing recommendations for H2O LLM Studio?">​</a></h3><p>When it comes to hardware requirements, it is important to note that the primary demand centers around the GPU and its associated VRAM. In terms of CPUs, most modern choices should suffice as NLP tasks typically do not heavily stress CPU performance. As for RAM, it&#x27;s advisable to have a minimum of 128GB, with a stronger recommendation of 256GB or more, particularly when dealing with substantial model weights that must be accommodated in the CPU RAM.</p><hr><hr><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Feedback</div><div class="admonitionContent_S0QG"><ul><li><a href="https://github.com/h2oai/docs-issues-requests/issues/new?assignees=sherenem&amp;labels=llmstudio&amp;body=%23%23%23%20Documentation%20issue%2Frequest%0A%0A%3C!--%20Please%20provide%20a%20clear%20and%20concise%20description%20of%20the%20documentation%20issue%2Frequest%20--%3E%0A%0A%23%23%23%20Additional%20context%0A%0A%3C!--%20Please%20add%20any%20other%20context%20about%20the%20issue%2Frequest%20here%20(e.g.%2C%20images)%20--%3E%0A%0A%23%23%23%20Page%20details%20%0A%0A-%20Application%20name%3A%20H2O LLM Studio | Docs%0A-%20Application%20version%3A%200.0.0%0A-%20Page%20title%3A%20/h2o-llmstudio/faqs%20&amp;title=%5BHAIC-APP%5D" target="_blank" rel="noopener noreferrer">Submit and view feedback for this page</a></li><li>Send feedback about H2O LLM Studio | Docs to <a href="mailto:cloud-feedback@h2o.ai" target="_blank" rel="noopener noreferrer">cloud-feedback@h2o.ai</a></li></ul></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/h2o-llmstudio/guide/experiments/evaluate-model-using-llm"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Evaluate model using an AI judge</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-are-the-general-recommendations-for-using-h2o-llm-studio" class="table-of-contents__link toc-highlight">What are the general recommendations for using H2O LLM Studio?</a></li><li><a href="#is-the-tool-multi-user-or-single-user" class="table-of-contents__link toc-highlight">Is the tool multi-user or single user?</a></li><li><a href="#how-can-human-feedback-be-applied-in-llm-studio" class="table-of-contents__link toc-highlight">How can human feedback be applied in LLM Studio?</a></li><li><a href="#how-does-h2o-llm-studio-evaluate-the-fine-tuned-model" class="table-of-contents__link toc-highlight">How does H2O LLM Studio evaluate the fine-tuned model?</a></li><li><a href="#can-i-use-a-different-ai-judge-than-chatgpt" class="table-of-contents__link toc-highlight">Can I use a different AI Judge than ChatGPT?</a></li><li><a href="#how-much-data-is-generally-required-to-fine-tune-a-model" class="table-of-contents__link toc-highlight">How much data is generally required to fine-tune a model?</a></li><li><a href="#are-there-any-recommendations-for-which-backbone-to-use-are-some-backbones-better-for-certain-types-of-tasks" class="table-of-contents__link toc-highlight">Are there any recommendations for which backbone to use? Are some backbones better for certain types of tasks?</a></li><li><a href="#what-if-my-data-is-not-in-question-and-answer-form-and-i-just-have-documents-how-can-i-fine-tune-the-llm-model" class="table-of-contents__link toc-highlight">What if my data is not in question-and-answer form and I just have documents? How can I fine-tune the LLM model?</a></li><li><a href="#can-the-adapter-be-downloaded-after-fine-tuning-so-that-the-adapter-can-be-combined-with-the-backbone-llm-for-deployment" class="table-of-contents__link toc-highlight">Can the adapter be downloaded after fine-tuning so that the adapter can be combined with the backbone LLM for deployment?</a></li><li><a href="#i-encounter-gpu-out-of-memory-issues-what-can-i-change-to-be-able-to-train-large-models" class="table-of-contents__link toc-highlight">I encounter GPU out-of-memory issues. What can I change to be able to train large models?</a></li><li><a href="#when-does-the-model-stop-the-fine-tuning-process" class="table-of-contents__link toc-highlight">When does the model stop the fine-tuning process?</a></li><li><a href="#what-is-the-maximum-dataset-size-that-an-llm-studio-instance-can-handle" class="table-of-contents__link toc-highlight">What is the maximum dataset size that an LLM Studio instance can handle?</a></li><li><a href="#where-does-h2o-llm-studio-store-its-data" class="table-of-contents__link toc-highlight">Where does H2O LLM Studio store its data?</a></li><li><a href="#how-can-i-update-h2o-llm-studio" class="table-of-contents__link toc-highlight">How can I update H2O LLM Studio?</a></li><li><a href="#once-i-have-the-lora-what-is-the-recommended-way-of-utilizing-it-with-the-base-model" class="table-of-contents__link toc-highlight">Once I have the LoRA, what is the recommended way of utilizing it with the base model?</a></li><li><a href="#how-to-use-h2o-llm-studio-in-windows" class="table-of-contents__link toc-highlight">How to use H2O LLM Studio in Windows?</a></li><li><a href="#how-can-i-easily-fine-tune-a-large-language-model-llm-using-the-command-line-interface-cli-of-h2o-llm-studio-when-i-have-limited-gpu-memory" class="table-of-contents__link toc-highlight">How can I easily fine-tune a large language model (LLM) using the command-line interface (CLI) of H2O LLM Studio when I have limited GPU memory?</a></li><li><a href="#can-i-run-a-validation-metric-on-a-model-post-training-optionally-on-a-different-validation-dataset" class="table-of-contents__link toc-highlight">Can I run a validation metric on a model post-training, optionally on a different validation dataset?</a></li><li><a href="#what-are-the-hardwareinfrastructure-sizing-recommendations-for-h2o-llm-studio" class="table-of-contents__link toc-highlight">What are the hardware/infrastructure sizing recommendations for H2O LLM Studio?</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://h2o.ai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">H2O.AI<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://h2o.ai/company/contact-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact us<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://h2o.ai/legal/privacy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://h2o.ai/insights/responsible-ai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Compliance &amp; responsible AI<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://twitter.com/h2oai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/h2oai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/c/H2Oai" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 <a href="https://h2o.ai" style="color:#FFE600">H2O.ai</a>, Inc.</div></div></div></footer></div>
<script src="/h2o-llmstudio/assets/js/runtime~main.cca6fbe9.js"></script>
<script src="/h2o-llmstudio/assets/js/main.b23f85b2.js"></script>
</body>
</html>